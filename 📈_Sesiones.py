import streamlit as st
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import datetime
import plotly.express as px
import os
import sys
import io

# --- ConfiguraciÃ³n Inicial del Proyecto y TÃ­tulo de la PÃ¡gina ---
try:
    project_root = os.path.abspath(
        os.path.join(os.path.dirname(__file__), os.pardir))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
except NameError:
    project_root = os.getcwd()
    if project_root not in sys.path:
        sys.path.insert(0, project_root)

st.set_page_config(layout="wide", page_title="AnÃ¡lisis de Sesiones y SQL")
st.title("ðŸ“Š AnÃ¡lisis de Sesiones y Calificaciones SQL")
st.markdown(
    "MÃ©tricas por LG, AE, PaÃ­s, CalificaciÃ³n SQL (SQL1 > SQL2 > MQL > NA > Sin CalificaciÃ³n), Puesto y Empresa."
)

# --- Constantes ---
CREDS_PATH = "credenciales.json"
SHEET_URL_SESIONES = "https://docs.google.com/spreadsheets/d/1Cejc7xfxd62qqsbzBOMRSI9HiJjHe_JSFnjf3lrXai4/edit?gid=1354854902#gid=1354854902"
SHEET_NAME_SESIONES = "Sesiones 2024-2025"

COLUMNAS_ESPERADAS = [
    "Semana", "Mes", "Fecha", "SQL", "Empresa", "PaÃ­s", "Nombre", "Apellido",
    "Puesto", "Email", "AE", "LG", "Siguientes Pasos", "RPA"
]
COLUMNAS_DERIVADAS = [
    'AÃ±o', 'NumSemana', 'MesNombre', 'AÃ±oMes', 'SQL_Estandarizado'
]
SQL_ORDER_OF_IMPORTANCE = ['SQL1', 'SQL2', 'MQL', 'NA', 'SIN CALIFICACIÃ“N SQL']

# --- GestiÃ³n de Estado de SesiÃ³n para Filtros ---
FILTER_KEYS_PREFIX = "sesiones_sql_lg_pais_page_v1_"
SES_START_DATE_KEY = f"{FILTER_KEYS_PREFIX}start_date"
SES_END_DATE_KEY = f"{FILTER_KEYS_PREFIX}end_date"
SES_AE_FILTER_KEY = f"{FILTER_KEYS_PREFIX}ae"
SES_LG_FILTER_KEY = f"{FILTER_KEYS_PREFIX}lg"
SES_PAIS_FILTER_KEY = f"{FILTER_KEYS_PREFIX}pais"
SES_YEAR_FILTER_KEY = f"{FILTER_KEYS_PREFIX}year"
SES_WEEK_FILTER_KEY = f"{FILTER_KEYS_PREFIX}week"
SES_SQL_FILTER_KEY = f"{FILTER_KEYS_PREFIX}sql_val"

default_filters_config = {
    SES_START_DATE_KEY: None,
    SES_END_DATE_KEY: None,
    SES_AE_FILTER_KEY: ["â€“ Todos â€“"],
    SES_LG_FILTER_KEY: ["â€“ Todos â€“"],
    SES_PAIS_FILTER_KEY: ["â€“ Todos â€“"],
    SES_YEAR_FILTER_KEY: "â€“ Todos â€“",
    SES_WEEK_FILTER_KEY: ["â€“ Todas â€“"],
    SES_SQL_FILTER_KEY: ["â€“ Todos â€“"]
}
for key, value in default_filters_config.items():
    if key not in st.session_state: st.session_state[key] = value


# --- Funciones de Utilidad ---
def parse_date_robust(date_val):
    if pd.isna(date_val) or str(date_val).strip() == "": return None
    try:
        return pd.to_datetime(date_val, format='%d/%m/%Y', errors='raise')
    except ValueError:
        try:
            return pd.to_datetime(date_val, errors='raise')
        except Exception:
            return None
    except Exception:
        return None


@st.cache_data(ttl=300)
def load_sesiones_data():
    try:
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive"
        ]
        creds = ServiceAccountCredentials.from_json_keyfile_name(
            CREDS_PATH, scope)
        client = gspread.authorize(creds)
        workbook = client.open_by_url(SHEET_URL_SESIONES)
        try:
            sheet = workbook.worksheet(SHEET_NAME_SESIONES)
        except gspread.exceptions.WorksheetNotFound:
            st.error(f"PestaÃ±a '{SHEET_NAME_SESIONES}' no encontrada.")
            return pd.DataFrame(columns=COLUMNAS_ESPERADAS +
                                COLUMNAS_DERIVADAS)
        raw_data = sheet.get_all_values()
        if not raw_data:
            st.error(f"PestaÃ±a '{SHEET_NAME_SESIONES}' vacÃ­a.")
            return pd.DataFrame(columns=COLUMNAS_ESPERADAS +
                                COLUMNAS_DERIVADAS)

        headers_cleaned = [str(h).strip() for h in raw_data[0]]
        final_df_headers = [h for h in headers_cleaned if h]
        data_rows = [row[:len(final_df_headers)] for row in raw_data[1:]]
        df = pd.DataFrame(data_rows, columns=final_df_headers)

        if "Fecha" not in df.columns:
            st.error("Columna 'Fecha' no encontrada.")
            return pd.DataFrame(columns=COLUMNAS_ESPERADAS +
                                COLUMNAS_DERIVADAS)
        df["Fecha"] = df["Fecha"].apply(parse_date_robust)
        df.dropna(subset=["Fecha"], inplace=True)
        if df.empty:
            st.warning("No hay sesiones con fechas vÃ¡lidas.")
            return pd.DataFrame(columns=COLUMNAS_ESPERADAS +
                                COLUMNAS_DERIVADAS)

        df['AÃ±o'] = df['Fecha'].dt.year.astype('Int64')
        df['NumSemana'] = df['Fecha'].dt.isocalendar().week.astype('Int64')
        df['MesNombre'] = df['Fecha'].dt.month_name()
        df['AÃ±oMes'] = df['Fecha'].dt.strftime('%Y-%m')

        if "SQL" not in df.columns: df["SQL"] = ""
        df['SQL_Estandarizado'] = df['SQL'].astype(str).str.strip().str.upper()
        known_sql_values = [
            s for s in SQL_ORDER_OF_IMPORTANCE if s != 'SIN CALIFICACIÃ“N SQL'
        ]
        mask_empty_sql = ~df['SQL_Estandarizado'].isin(known_sql_values) & (
            df['SQL_Estandarizado'].isin(['', 'NAN', 'NONE'])
            | df['SQL_Estandarizado'].isna())
        df.loc[mask_empty_sql, 'SQL_Estandarizado'] = 'SIN CALIFICACIÃ“N SQL'
        df.loc[df['SQL_Estandarizado'] == '',
               'SQL_Estandarizado'] = 'SIN CALIFICACIÃ“N SQL'

        for col_actor, default_actor_name in [("AE", "No Asignado AE"),
                                              ("LG", "No Asignado LG")]:
            if col_actor not in df.columns: df[col_actor] = default_actor_name
            df[col_actor] = df[col_actor].astype(str).str.strip()
            df.loc[df[col_actor].isin(['', 'nan', 'none', 'NaN', 'None']),
                   col_actor] = default_actor_name

        for col_clean in ["Puesto", "Empresa", "PaÃ­s"]:
            if col_clean not in df.columns: df[col_clean] = "No Especificado"
            df[col_clean] = df[col_clean].astype(str).str.strip()
            df.loc[df[col_clean].isin(['', 'nan', 'none', 'NaN', 'None']),
                   col_clean] = 'No Especificado'

        df_final = pd.DataFrame()
        all_final_cols = COLUMNAS_ESPERADAS + COLUMNAS_DERIVADAS
        for col in all_final_cols:
            if col in df.columns: df_final[col] = df[col]
            else:
                if col in COLUMNAS_ESPERADAS and col not in df.columns:
                    st.warning(f"Col. original '{col}' no encontrada.")
                if col in ['AÃ±o', 'NumSemana']:
                    df_final[col] = pd.Series(dtype='Int64')
                elif col == 'Fecha':
                    df_final[col] = pd.Series(dtype='datetime64[ns]')
                else:
                    df_final[col] = pd.Series(dtype='object')
        return df_final
    except FileNotFoundError:
        st.error(f"Error CrÃ­tico: Archivo '{CREDS_PATH}' no encontrado.")
        return pd.DataFrame(columns=COLUMNAS_ESPERADAS + COLUMNAS_DERIVADAS)
    except gspread.exceptions.APIError as e:
        st.error(f"Error CrÃ­tico API Google: {e}")
        return pd.DataFrame(columns=COLUMNAS_ESPERADAS + COLUMNAS_DERIVADAS)
    except Exception as e:
        st.error(f"Error inesperado en carga: {e}")
        st.exception(e)
        return pd.DataFrame()


def clear_ses_filters_callback():
    for key, value in default_filters_config.items():
        st.session_state[key] = value
    st.toast("Filtros reiniciados âœ…", icon="ðŸ§¹")


def sidebar_filters_sesiones(df_options):
    st.sidebar.header("ðŸ” Filtros de Sesiones")
    st.sidebar.markdown("---")
    min_d, max_d = (df_options["Fecha"].min().date(), df_options["Fecha"].max(
    ).date()) if "Fecha" in df_options and not df_options["Fecha"].dropna(
    ).empty and pd.api.types.is_datetime64_any_dtype(
        df_options["Fecha"]) else (None, None)
    c1, c2 = st.sidebar.columns(2)
    c1.date_input("Desde",
                  value=st.session_state[SES_START_DATE_KEY],
                  min_value=min_d,
                  max_value=max_d,
                  format="DD/MM/YYYY",
                  key=SES_START_DATE_KEY)
    c2.date_input("Hasta",
                  value=st.session_state[SES_END_DATE_KEY],
                  min_value=min_d,
                  max_value=max_d,
                  format="DD/MM/YYYY",
                  key=SES_END_DATE_KEY)

    st.sidebar.markdown("---")
    years = ["â€“ Todos â€“"
             ] + (sorted(df_options["AÃ±o"].dropna().astype(int).unique(),
                         reverse=True) if "AÃ±o" in df_options
                  and not df_options["AÃ±o"].dropna().empty else [])
    current_year_val_in_state = st.session_state[SES_YEAR_FILTER_KEY]
    if current_year_val_in_state not in years:
        st.session_state[SES_YEAR_FILTER_KEY] = "â€“ Todos â€“"
    st.sidebar.selectbox("AÃ±o", years, key=SES_YEAR_FILTER_KEY)
    sel_y = int(
        st.session_state[SES_YEAR_FILTER_KEY]
    ) if st.session_state[SES_YEAR_FILTER_KEY] != "â€“ Todos â€“" else None

    weeks_df = df_options[
        df_options["AÃ±o"] ==
        sel_y] if sel_y is not None and "AÃ±o" in df_options.columns else df_options
    weeks = ["â€“ Todas â€“"
             ] + (sorted(weeks_df["NumSemana"].dropna().astype(int).unique())
                  if "NumSemana" in weeks_df
                  and not weeks_df["NumSemana"].dropna().empty else [])
    current_week_selection_in_state = st.session_state[SES_WEEK_FILTER_KEY]
    validated_week_selection = [
        val for val in current_week_selection_in_state if val in weeks
    ]
    if not validated_week_selection:
        st.session_state[SES_WEEK_FILTER_KEY] = [
            "â€“ Todas â€“"
        ] if "â€“ Todas â€“" in weeks else (
            [weeks[0]] if weeks and weeks[0] != "â€“ Todas â€“" else [])
    elif len(validated_week_selection) != len(current_week_selection_in_state):
        st.session_state[SES_WEEK_FILTER_KEY] = validated_week_selection
    st.sidebar.multiselect("Semanas", weeks, key=SES_WEEK_FILTER_KEY)

    st.sidebar.markdown("---")
    st.sidebar.subheader("ðŸ‘¥ Por Analistas, PaÃ­s y CalificaciÃ³n")

    lgs_options = ["â€“ Todos â€“"] + (sorted(df_options["LG"].dropna().unique(
    )) if "LG" in df_options and not df_options["LG"].dropna().empty else [])
    current_lg_selection_in_state = st.session_state[SES_LG_FILTER_KEY]
    validated_lg_selection = [
        val for val in current_lg_selection_in_state if val in lgs_options
    ]
    if not validated_lg_selection:
        st.session_state[SES_LG_FILTER_KEY] = [
            "â€“ Todos â€“"
        ] if "â€“ Todos â€“" in lgs_options else (
            [lgs_options[0]]
            if lgs_options and lgs_options[0] != "â€“ Todos â€“" else [])
    elif len(validated_lg_selection) != len(current_lg_selection_in_state):
        st.session_state[SES_LG_FILTER_KEY] = validated_lg_selection
    st.sidebar.multiselect("Analista LG", lgs_options, key=SES_LG_FILTER_KEY)

    ae_options = ["â€“ Todos â€“"] + (sorted(df_options["AE"].dropna().unique(
    )) if "AE" in df_options and not df_options["AE"].dropna().empty else [])
    current_ae_selection_in_state = st.session_state[SES_AE_FILTER_KEY]
    validated_ae_selection = [
        val for val in current_ae_selection_in_state if val in ae_options
    ]
    if not validated_ae_selection:
        st.session_state[SES_AE_FILTER_KEY] = [
            "â€“ Todos â€“"
        ] if "â€“ Todos â€“" in ae_options else (
            [ae_options[0]]
            if ae_options and ae_options[0] != "â€“ Todos â€“" else [])
    elif len(validated_ae_selection) != len(current_ae_selection_in_state):
        st.session_state[SES_AE_FILTER_KEY] = validated_ae_selection
    st.sidebar.multiselect("Account Executive (AE)",
                           ae_options,
                           key=SES_AE_FILTER_KEY)

    paises_opts = ["â€“ Todos â€“"] + (
        sorted(df_options["PaÃ­s"].dropna().unique()) if "PaÃ­s" in df_options
        and not df_options["PaÃ­s"].dropna().empty else [])
    current_pais_selection_in_state = st.session_state[SES_PAIS_FILTER_KEY]
    validated_pais_selection = [
        val for val in current_pais_selection_in_state if val in paises_opts
    ]
    if not validated_pais_selection:
        st.session_state[SES_PAIS_FILTER_KEY] = [
            "â€“ Todos â€“"
        ] if "â€“ Todos â€“" in paises_opts else (
            [paises_opts[0]]
            if paises_opts and paises_opts[0] != "â€“ Todos â€“" else [])
    elif len(validated_pais_selection) != len(current_pais_selection_in_state):
        st.session_state[SES_PAIS_FILTER_KEY] = validated_pais_selection
    st.sidebar.multiselect("PaÃ­s", paises_opts, key=SES_PAIS_FILTER_KEY)

    sqls_opts = ["â€“ Todos â€“"] + (
        sorted(df_options["SQL_Estandarizado"].dropna().unique(),
               key=lambda x: SQL_ORDER_OF_IMPORTANCE.index(x) if x in
               SQL_ORDER_OF_IMPORTANCE else len(SQL_ORDER_OF_IMPORTANCE))
        if "SQL_Estandarizado" in df_options
        and not df_options["SQL_Estandarizado"].dropna().empty else [])
    current_sql_selection_in_state = st.session_state[SES_SQL_FILTER_KEY]
    validated_sql_selection = [
        val for val in current_sql_selection_in_state if val in sqls_opts
    ]
    if not validated_sql_selection:
        st.session_state[SES_SQL_FILTER_KEY] = [
            "â€“ Todos â€“"
        ] if "â€“ Todos â€“" in sqls_opts else (
            [sqls_opts[0]]
            if sqls_opts and sqls_opts[0] != "â€“ Todos â€“" else [])
    elif len(validated_sql_selection) != len(current_sql_selection_in_state):
        st.session_state[SES_SQL_FILTER_KEY] = validated_sql_selection
    st.sidebar.multiselect("CalificaciÃ³n SQL",
                           sqls_opts,
                           key=SES_SQL_FILTER_KEY)

    st.sidebar.markdown("---")
    st.sidebar.button("ðŸ§¹ Limpiar Todos los Filtros",
                      on_click=clear_ses_filters_callback,
                      use_container_width=True,
                      key=f"{FILTER_KEYS_PREFIX}btn_clear")
    return (st.session_state[SES_START_DATE_KEY],
            st.session_state[SES_END_DATE_KEY], sel_y,
            st.session_state[SES_WEEK_FILTER_KEY],
            st.session_state[SES_AE_FILTER_KEY],
            st.session_state[SES_LG_FILTER_KEY],
            st.session_state[SES_PAIS_FILTER_KEY],
            st.session_state[SES_SQL_FILTER_KEY])


def apply_sesiones_filters(df, start_date, end_date, year_f, week_f, ae_f,
                           lg_f, pais_f, sql_f):
    if df is None or df.empty: return pd.DataFrame()
    df_f = df.copy()
    if "Fecha" in df_f.columns and pd.api.types.is_datetime64_any_dtype(
            df_f["Fecha"]):
        if start_date and end_date:
            df_f = df_f[(df_f["Fecha"].dt.date >= start_date)
                        & (df_f["Fecha"].dt.date <= end_date)]
        elif start_date:
            df_f = df_f[df_f["Fecha"].dt.date >= start_date]
        elif end_date:
            df_f = df_f[df_f["Fecha"].dt.date <= end_date]
    if year_f is not None and "AÃ±o" in df_f.columns:
        df_f = df_f[df_f["AÃ±o"] == year_f]
    if week_f and "â€“ Todas â€“" not in week_f and "NumSemana" in df_f.columns:
        valid_w = [
            int(w) for w in week_f
            if (isinstance(w, str) and w.isdigit()) or isinstance(w, int)
        ]
        if valid_w: df_f = df_f[df_f["NumSemana"].isin(valid_w)]
    if ae_f and "â€“ Todos â€“" not in ae_f and "AE" in df_f.columns:
        df_f = df_f[df_f["AE"].isin(ae_f)]
    if lg_f and "â€“ Todos â€“" not in lg_f and "LG" in df_f.columns:
        df_f = df_f[df_f["LG"].isin(lg_f)]
    if pais_f and "â€“ Todos â€“" not in pais_f and "PaÃ­s" in df_f.columns:
        df_f = df_f[df_f["PaÃ­s"].isin(pais_f)]
    if sql_f and "â€“ Todos â€“" not in sql_f and "SQL_Estandarizado" in df_f.columns:
        df_f = df_f[df_f["SQL_Estandarizado"].isin(sql_f)]
    return df_f


def get_sql_category_order(df_column_or_list):
    present_sqls = pd.Series(df_column_or_list).unique()
    ordered_present_sqls = [
        s for s in SQL_ORDER_OF_IMPORTANCE if s in present_sqls
    ]
    other_sqls = sorted(
        [s for s in present_sqls if s not in ordered_present_sqls])
    return ordered_present_sqls + other_sqls


def display_sesiones_summary_sql(df_filtered):
    st.markdown("### ðŸ“Œ Resumen Principal de Sesiones")
    if df_filtered.empty:
        st.info("No hay sesiones para resumen.")
        return
    total_sesiones = len(df_filtered)
    st.metric("Total Sesiones (filtradas)", f"{total_sesiones:,}")
    if 'SQL_Estandarizado' in df_filtered.columns:
        st.markdown("#### DistribuciÃ³n por CalificaciÃ³n SQL")
        # CORRECCIÃ“N: Eliminar observed=True de value_counts si da error, o ajustar segÃºn versiÃ³n de Pandas.
        # Para compatibilidad con versiones mÃ¡s antiguas, se elimina.
        sql_counts = df_filtered['SQL_Estandarizado'].value_counts(
        ).reset_index()
        sql_counts.columns = ['CalificaciÃ³n SQL', 'NÃºmero de Sesiones']

        category_order = get_sql_category_order(sql_counts['CalificaciÃ³n SQL'])
        sql_counts['CalificaciÃ³n SQL'] = pd.Categorical(
            sql_counts['CalificaciÃ³n SQL'],
            categories=category_order,
            ordered=True)
        sql_counts = sql_counts.sort_values('CalificaciÃ³n SQL')
        if not sql_counts.empty:
            fig = px.bar(sql_counts,
                         x='CalificaciÃ³n SQL',
                         y='NÃºmero de Sesiones',
                         title='Sesiones por CalificaciÃ³n SQL',
                         text_auto=True,
                         color='CalificaciÃ³n SQL',
                         category_orders={"CalificaciÃ³n SQL": category_order})
            st.plotly_chart(fig, use_container_width=True)
            st.dataframe(sql_counts.set_index('CalificaciÃ³n SQL').style.format(
                {"NÃºmero de Sesiones": "{:,}"}),
                         use_container_width=True)
    else:
        st.warning("Columna 'SQL_Estandarizado' no encontrada.")


def display_analisis_por_dimension(df_filtered,
                                   dimension_col,
                                   dimension_label,
                                   top_n=10):
    st.markdown(
        f"### ðŸ“Š AnÃ¡lisis por {dimension_label} y CalificaciÃ³n SQL (Top {top_n})"
    )
    if df_filtered.empty or dimension_col not in df_filtered.columns or 'SQL_Estandarizado' not in df_filtered.columns:
        st.info(f"Datos insuficientes para anÃ¡lisis por {dimension_label}.")
        return

    sql_category_order = get_sql_category_order(
        df_filtered['SQL_Estandarizado'])

    summary_dim_sql = df_filtered.groupby(
        [dimension_col, 'SQL_Estandarizado'], as_index=False,
        observed=True)['Fecha'].count().rename(
            columns={'Fecha': 'Cantidad_SQL'})

    dim_totals = df_filtered.groupby(dimension_col,
                                     as_index=False,
                                     observed=True)['Fecha'].count().rename(
                                         columns={'Fecha': 'Total_Sesiones'})

    top_n_dims = dim_totals.sort_values(
        by='Total_Sesiones',
        ascending=False).head(top_n)[dimension_col].tolist()
    summary_dim_sql_top_n = summary_dim_sql[
        summary_dim_sql[dimension_col].isin(top_n_dims)].copy()

    if summary_dim_sql_top_n.empty:
        st.info(f"No hay datos agregados por {dimension_label} y SQL.")
        return

    summary_dim_sql_top_n['SQL_Estandarizado'] = pd.Categorical(
        summary_dim_sql_top_n['SQL_Estandarizado'],
        categories=sql_category_order,
        ordered=True)

    if not summary_dim_sql_top_n.empty:
        fig = px.bar(summary_dim_sql_top_n,
                     x=dimension_col,
                     y='Cantidad_SQL',
                     color='SQL_Estandarizado',
                     title=f'DistribuciÃ³n de SQL por {dimension_label}',
                     barmode='stack',
                     category_orders={
                         dimension_col: top_n_dims,
                         "SQL_Estandarizado": sql_category_order
                     },
                     color_discrete_sequence=px.colors.qualitative.Vivid)
        fig.update_layout(xaxis_tickangle=-45,
                          yaxis_title="NÃºmero de Sesiones")
        st.plotly_chart(fig, use_container_width=True)

    pivot_table = summary_dim_sql_top_n.pivot_table(
        index=dimension_col,
        columns='SQL_Estandarizado',
        values='Cantidad_SQL',
        fill_value=0)
    for sql_cat in sql_category_order:
        if sql_cat not in pivot_table.columns: pivot_table[sql_cat] = 0
    pivot_table_cols_ordered = [col for col in sql_category_order if col in pivot_table.columns] + \
                               [col for col in pivot_table.columns if col not in sql_category_order]
    pivot_table = pivot_table.reindex(columns=pivot_table_cols_ordered,
                                      fill_value=0)
    pivot_table = pivot_table.reindex(index=top_n_dims, fill_value=0)
    pivot_table['Total_Sesiones_Dim'] = pivot_table.sum(axis=1)

    for col in pivot_table.columns:
        try:
            pivot_table[col] = pd.to_numeric(
                pivot_table[col], errors='coerce').fillna(0).astype(int)
        except ValueError:
            st.warning(
                f"Advertencia: Col '{col}' en pivot_table no pudo ser convertida a entero."
            )
            pivot_table[col] = pivot_table[col].astype(str)

    format_dict = {
        col: "{:,.0f}"
        for col in pivot_table.columns
        if pd.api.types.is_numeric_dtype(pivot_table[col])
    }
    if format_dict:
        st.dataframe(pivot_table.style.format(format_dict),
                     use_container_width=True)
    else:
        st.dataframe(pivot_table, use_container_width=True)


def display_evolucion_sql(df_filtered, time_agg_col, display_label,
                          chart_title, x_axis_label):
    st.markdown(f"### ðŸ“ˆ {chart_title}")
    if df_filtered.empty or 'SQL_Estandarizado' not in df_filtered.columns:
        st.info(f"Datos insuficientes.")
        return
    df_agg = df_filtered.copy()
    group_col = time_agg_col
    if time_agg_col == 'NumSemana':
        if not ('AÃ±o' in df_agg.columns and 'NumSemana' in df_agg.columns):
            st.warning("Faltan AÃ±o/NumSemana.")
            return
        df_agg.dropna(subset=['AÃ±o', 'NumSemana'], inplace=True)
        if df_agg.empty:
            st.info("No hay datos para evoluciÃ³n semanal.")
            return
        df_agg['AÃ±o-Semana'] = df_agg['AÃ±o'].astype(int).astype(
            str) + '-S' + df_agg['NumSemana'].astype(int).astype(
                str).str.zfill(2)
        group_col = 'AÃ±o-Semana'
        df_agg = df_agg.sort_values(by=group_col)
    elif time_agg_col == 'AÃ±oMes':
        if 'AÃ±oMes' not in df_agg.columns:
            st.warning("Columna 'AÃ±oMes' faltante.")
            return
        df_agg = df_agg.sort_values(by='AÃ±oMes')

    sql_category_order = get_sql_category_order(df_agg['SQL_Estandarizado'])
    summary_time_sql = df_agg.groupby(
        [group_col, 'SQL_Estandarizado'], as_index=False,
        observed=True)['Fecha'].count().rename(
            columns={'Fecha': 'NÃºmero de Sesiones'})

    if summary_time_sql.empty:
        st.info(f"No hay datos agregados por {x_axis_label.lower()} y SQL.")
        return
    summary_time_sql['SQL_Estandarizado'] = pd.Categorical(
        summary_time_sql['SQL_Estandarizado'],
        categories=sql_category_order,
        ordered=True)
    summary_time_sql = summary_time_sql.sort_values(
        [group_col, 'SQL_Estandarizado'])
    st.dataframe(summary_time_sql.style.format({"NÃºmero de Sesiones": "{:,}"}),
                 use_container_width=True)
    try:
        fig = px.line(
            summary_time_sql,
            x=group_col,
            y='NÃºmero de Sesiones',
            color='SQL_Estandarizado',
            title=f"EvoluciÃ³n por SQL ({x_axis_label})",
            markers=True,
            category_orders={"SQL_Estandarizado": sql_category_order})
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"No se pudo generar grÃ¡fico: {e}")


def display_tabla_sesiones_detalle(df_filtered):
    st.markdown("### ðŸ“ Tabla Detallada de Sesiones")
    if df_filtered.empty:
        st.info("No hay sesiones detalladas para mostrar.")
        return
    cols_display = [
        "Fecha", "LG", "AE", "PaÃ­s", "SQL", "SQL_Estandarizado", "Empresa",
        "Puesto", "Nombre", "Apellido", "Siguientes Pasos"
    ]
    cols_present = [col for col in cols_display if col in df_filtered.columns]
    df_view = df_filtered[cols_present].copy()
    if "Fecha" in df_view.columns and pd.api.types.is_datetime64_any_dtype(
            df_view["Fecha"]):
        df_view["Fecha"] = pd.to_datetime(
            df_view["Fecha"]).dt.strftime('%d/%m/%Y')
    st.dataframe(df_view, height=400, use_container_width=True)
    if not df_view.empty:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df_view.to_excel(writer,
                             index=False,
                             sheet_name='Detalle_Sesiones')
        st.download_button(
            label="â¬‡ï¸ Descargar Detalle (Excel)",
            data=output.getvalue(),
            file_name="detalle_sesiones_sql.xlsx",
            mime=
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key=f"{FILTER_KEYS_PREFIX}btn_download_detalle")


# --- Flujo Principal de la PÃ¡gina ---
df_sesiones_raw = load_sesiones_data()
if df_sesiones_raw is None or df_sesiones_raw.empty:
    st.error("Fallo CrÃ­tico al cargar datos. La pÃ¡gina no puede continuar.")
    st.stop()

start_f, end_f, year_f, week_f, ae_f, lg_f, pais_f, sql_f_val = sidebar_filters_sesiones(
    df_sesiones_raw)
df_sesiones_filtered = apply_sesiones_filters(df_sesiones_raw, start_f, end_f,
                                              year_f, week_f, ae_f, lg_f,
                                              pais_f, sql_f_val)

display_sesiones_summary_sql(df_sesiones_filtered)
st.markdown("---")
display_analisis_por_dimension(df_filtered=df_sesiones_filtered,
                               dimension_col="LG",
                               dimension_label="Analista LG",
                               top_n=15)
st.markdown("---")
display_analisis_por_dimension(df_filtered=df_sesiones_filtered,
                               dimension_col="AE",
                               dimension_label="Account Executive",
                               top_n=15)
st.markdown("---")
display_analisis_por_dimension(df_filtered=df_sesiones_filtered,
                               dimension_col="PaÃ­s",
                               dimension_label="PaÃ­s",
                               top_n=10)
st.markdown("---")
display_analisis_por_dimension(df_filtered=df_sesiones_filtered,
                               dimension_col="Puesto",
                               dimension_label="Cargo (Puesto)",
                               top_n=10)
st.markdown("---")
display_analisis_por_dimension(df_filtered=df_sesiones_filtered,
                               dimension_col="Empresa",
                               dimension_label="Empresa",
                               top_n=10)
st.markdown("---")
display_evolucion_sql(df_sesiones_filtered, 'NumSemana', 'AÃ±o-Semana',
                      "EvoluciÃ³n Semanal por CalificaciÃ³n SQL",
                      "Semana del AÃ±o")
st.markdown("---")
display_evolucion_sql(df_sesiones_filtered, 'AÃ±oMes', 'AÃ±o-Mes',
                      "EvoluciÃ³n Mensual por CalificaciÃ³n SQL", "Mes del AÃ±o")
st.markdown("---")
display_tabla_sesiones_detalle(df_sesiones_filtered)

# --- PIE DE PÃGINA ---
st.markdown("---")
st.info(
    "Esta maravillosa, caÃ³tica y probablemente sobrecafeinada plataforma ha sido realizada por Johnsito âœ¨ ðŸ˜Š"
)
